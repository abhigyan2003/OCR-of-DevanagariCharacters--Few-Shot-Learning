{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9980720,"sourceType":"datasetVersion","datasetId":6141495},{"sourceId":10012863,"sourceType":"datasetVersion","datasetId":6164519}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to create directories\ndef create_directories(output_dir, classes):\n    support_dir = os.path.join(output_dir, 'support')\n    query_dir = os.path.join(output_dir, 'query')\n    os.makedirs(support_dir, exist_ok=True)\n    os.makedirs(query_dir, exist_ok=True)\n    \n    for cls in classes:\n        os.makedirs(os.path.join(support_dir, cls), exist_ok=True)\n        os.makedirs(os.path.join(query_dir, cls), exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to load and save images in support and query folders\ndef load_and_save_images(directory, target_size, output_dir, support_ratio=2/3):\n    support_images, query_images, support_labels, query_labels = [], [], [], []\n    class_labels = sorted(os.listdir(directory))\n    label_map = {label: class_name for label, class_name in enumerate(class_labels)}\n    print(\"Label Map:\", label_map)\n    \n    create_directories(output_dir, class_labels)\n    \n    total_support_images = 0\n    total_query_images = 0\n\n    valid_extensions = ('.jpeg', '.jpg', '.png')\n    \n    for label, class_name in enumerate(class_labels):\n        class_path = os.path.join(directory, class_name)\n        images = [img for img in os.listdir(class_path) if img.lower().endswith(valid_extensions)]\n        np.random.shuffle(images)\n        \n        num_support = int(len(images) * support_ratio)\n        support_imgs = images[:num_support]\n        query_imgs = images[num_support:]\n        \n        total_support_images += len(support_imgs)\n        total_query_images += len(query_imgs)\n        \n        for img in support_imgs:\n            img_path = os.path.join(class_path, img)\n            try:\n                img_data = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n                img_array = tf.keras.preprocessing.image.img_to_array(img_data)\n                support_images.append(img_array)\n                support_labels.append(label)\n                img_data.save(os.path.join(output_dir, 'support', class_name, img))\n            except Exception as e:\n                print(f\"Skipping file {img_path}: {e}\")\n        \n        for img in query_imgs:\n            img_path = os.path.join(class_path, img)\n            try:\n                img_data = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n                img_array = tf.keras.preprocessing.image.img_to_array(img_data)\n                query_images.append(img_array)\n                query_labels.append(label)\n                img_data.save(os.path.join(output_dir, 'query', class_name, img))\n            except Exception as e:\n                print(f\"Skipping file {img_path}: {e}\")\n    \n    print(f\"Total support images loaded: {total_support_images}\")\n    print(f\"Total query images loaded: {total_query_images}\")\n    \n    return (np.array(support_images), np.array(support_labels), np.array(query_images), np.array(query_labels), class_labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to build the embedding model\ndef build_embedding_model(input_shape):\n    base_model = VGG16(include_top=False, input_shape=input_shape)\n    base_model.trainable = False  # Freeze the base model\n\n    input_layer = Input(shape=input_shape)\n    x = base_model(input_layer)\n    x = Flatten()(x)\n    embedding_model = Model(input_layer, x, name=\"embedding_model\")\n    return embedding_model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to calculate prototypes for each class\ndef compute_prototypes(embedding_model, support_images, support_labels, num_classes, batch_size=32):\n    embeddings = embedding_model.predict(support_images, batch_size=batch_size)\n    prototypes = []\n    for class_id in range(num_classes):\n        class_embeddings = embeddings[support_labels == class_id]\n\n        # Check if there are embeddings for the current class\n        if len(class_embeddings) > 0:\n            prototype = np.mean(class_embeddings, axis=0)\n        else:\n            prototype = np.zeros(embeddings.shape[1])  # Create a zero-vector for empty classes\n\n        prototypes.append(prototype)\n\n    return np.array(prototypes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to calculate pairwise distances\ndef pairwise_distances(a, b):\n    a = tf.cast(a, tf.float32)\n    b = tf.cast(b, tf.float32)\n    a = tf.expand_dims(a, axis=1)\n    b = tf.expand_dims(b, axis=0)\n    return tf.reduce_sum(tf.square(a - b), axis=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to evaluate the model on query set using prototypes\ndef evaluate_few_shot(embedding_model, query_images, query_labels, prototypes, class_labels, batch_size=32):\n    query_embeddings = embedding_model.predict(query_images, batch_size=batch_size)\n    distances = pairwise_distances(query_embeddings, prototypes)\n    predictions = np.argmin(distances, axis=1)\n    \n    accuracy = accuracy_score(query_labels, predictions)\n    precision = precision_score(query_labels, predictions, average='macro', zero_division=0)\n    recall = recall_score(query_labels, predictions, average='macro', zero_division=0)\n    f1 = f1_score(query_labels, predictions, average='macro', zero_division=0)\n    \n    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"Precision: {precision * 100:.2f}%\")\n    print(f\"Recall: {recall * 100:.2f}%\")\n    print(f\"F1 Score: {f1 * 100:.2f}%\")\n    \n    # Confusion Matrix\n    cm = confusion_matrix(query_labels, predictions)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title('Confusion Matrix')\n    plt.show()\n    \n    # Classification Report\n    report = classification_report(query_labels, predictions, target_names=class_labels, zero_division=0)\n    print('Classification Report:\\n', report)\n    \n    return accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define your directories and parameters\nroot_dir = \"/kaggle/input/devanagari-consonant-conjuncts-fsl/main\"\ntarget_size = (224, 224)\noutput_dir = \"/kaggle/working/\"\nnum_classes = len(os.listdir(root_dir))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load support and query sets and save images\ntrain_support_images, train_support_labels, train_query_images, train_query_labels, class_labels = load_and_save_images(\n    root_dir, target_size, output_dir, support_ratio=2/3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build the embedding model\ninput_shape = (224, 224, 3)\nembedding_model = build_embedding_model(input_shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate prototypes for the support set\ntrain_prototypes = compute_prototypes(embedding_model, train_support_images, train_support_labels, num_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the query set\nval_accuracy = evaluate_few_shot(embedding_model, train_query_images, train_query_labels, train_prototypes, class_labels)\nprint(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}